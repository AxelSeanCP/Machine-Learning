{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the kaggle.json from kaggle API into colab\n",
        "# do this command\n",
        "\n",
        "# install kaggle library\n",
        "!pip install kaggle\n",
        "# make a directory named .kaggle\n",
        "!mkdir ~/.kaggle\n",
        "# copy the kaggle.json into this new directory\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# alocate the required permission for this file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# download dataset\n",
        "!kaggle datasets download shivam2503/diamonds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W7HZEnGjl_O",
        "outputId": "8823d93f-31e8-45c5-c154-ccb35ec4a7b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading diamonds.zip to /content\n",
            "  0% 0.00/733k [00:00<?, ?B/s]\n",
            "100% 733k/733k [00:00<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3SDEGKB4hCOh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/natashayulian/diamond_dataset/master/diamonds.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "pTINvmR1lUH_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8h_5C1Alc5d",
        "outputId": "315eec30-7700-4cec-e760-ef4557d1dacc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34521 train examples\n",
            "8631 validation examples\n",
            "10788 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create target column\n",
        "# 0 = low, 1 = high\n",
        "df['target'] = np.where(df['price'] <= 1000, 0, 1)\n",
        "# drop un-used columns\n",
        "df = df.drop(columns=['price'])"
      ],
      "metadata": {
        "id": "V2dw4fqel5Qt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset tf.data from pandas dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = df.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size = len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds\n",
        "\n",
        "batch_size = 10 #small batch size for demonstration\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "5fnKS2U2mdrO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(train_ds))[0]\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "metadata": {
        "id": "w2F-BGf8nn9J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numeric columns\n",
        "carat = feature_column.numeric_column('carat')\n",
        "demo(carat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJcGK78uoY03",
        "outputId": "914bc214-a350-4c98-d466-ebd51b4903d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-288be7d6fcf1>:2: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7 ]\n",
            " [0.54]\n",
            " [0.41]\n",
            " [0.43]\n",
            " [0.32]\n",
            " [0.31]\n",
            " [1.47]\n",
            " [0.26]\n",
            " [0.4 ]\n",
            " [0.53]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bucketized column\n",
        "carat = feature_column.numeric_column('carat')\n",
        "carat_buckets = feature_column.bucketized_column(carat, boundaries=[1,2])\n",
        "demo(carat_buckets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKuyCxpqoZd1",
        "outputId": "66703dad-3488-4b55-9061-8962cf432f9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-7d16e048ab51>:3: bucketized_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical\n",
        "color_type = feature_column.categorical_column_with_vocabulary_list(\n",
        "    'color', ['E','I', 'J', 'D', 'H', 'G', 'F']\n",
        ")\n",
        "\n",
        "color_type_one_hot = feature_column.indicator_column(color_type)\n",
        "demo(color_type_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKEoM32nov-f",
        "outputId": "944ac861-1297-4ab4-c899-52ef840e63df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-082bc9d2fb73>:2: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-14-082bc9d2fb73>:6: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "clarity = feature_column.categorical_column_with_vocabulary_list(\n",
        "    'clarity', df.clarity.unique()\n",
        ")\n",
        "\n",
        "clarity_embedding = feature_column.embedding_column(clarity, dimension=6)\n",
        "demo(clarity_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EdsKujUpRDV",
        "outputId": "a891afcd-d31c-470b-ce57-ca9a14453515"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-6b90746fbc70>:6: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.62880474 -0.47700405 -0.33082196 -0.30582657 -0.13923575  0.7310454 ]\n",
            " [ 0.072032    0.6628276   0.3250774   0.5502012  -0.11018097  0.1510863 ]\n",
            " [ 0.32835105  0.7354041   0.09370571 -0.12796547  0.22361277 -0.13337669]\n",
            " [-0.47970665  0.34657586 -0.4382733  -0.04013623 -0.06052717 -0.509754  ]\n",
            " [ 0.62880474 -0.47700405 -0.33082196 -0.30582657 -0.13923575  0.7310454 ]\n",
            " [ 0.62880474 -0.47700405 -0.33082196 -0.30582657 -0.13923575  0.7310454 ]\n",
            " [ 0.32835105  0.7354041   0.09370571 -0.12796547  0.22361277 -0.13337669]\n",
            " [-0.8130617   0.41242817 -0.4093392  -0.22138116 -0.02640382  0.23072772]\n",
            " [ 0.62880474 -0.47700405 -0.33082196 -0.30582657 -0.13923575  0.7310454 ]\n",
            " [ 0.38724998 -0.22759522 -0.03395327  0.22571841 -0.01494894 -0.07700925]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hashed feature\n",
        "clarity_hashed = feature_column.categorical_column_with_hash_bucket(\n",
        "    'clarity', hash_bucket_size=5\n",
        ")\n",
        "demo(feature_column.indicator_column(clarity_hashed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2RO4HKpzZ1",
        "outputId": "60504305-988c-4e8b-d850-0b3865cf16fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-e9927287fa85>:2: categorical_column_with_hash_bucket (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# crossed feature\n",
        "# crossed data should be string, categorical, or bucketized\n",
        "crossed_feature = feature_column.crossed_column([carat_buckets, color_type], hash_bucket_size=10)\n",
        "demo(feature_column.indicator_column(crossed_feature))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaSUBp28qNpk",
        "outputId": "924ffeec-80aa-48c2-e8ca-a8b9bd1fdd08"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-f373c2f3b294>:3: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick which feature column to use\n",
        "feature_columns = []\n",
        "\n",
        "# numeric columns\n",
        "for header in ['carat', 'depth', 'x', 'y', 'z']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))\n",
        "\n",
        "# create feature layer\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "mZBQ39Yfq3e8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    feature_layer,\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dropout(.1),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_ds,validation_data = val_ds, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7-cwWIHr1fi",
        "outputId": "47070ca2-210f-41c3-b228-0d76d39007d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1686/1686 [==============================] - 9s 4ms/step - loss: 0.2070 - accuracy: 0.9099 - val_loss: 0.1479 - val_accuracy: 0.9365\n",
            "Epoch 2/10\n",
            "1686/1686 [==============================] - 9s 5ms/step - loss: 0.1597 - accuracy: 0.9333 - val_loss: 0.2269 - val_accuracy: 0.8926\n",
            "Epoch 3/10\n",
            "1686/1686 [==============================] - 7s 4ms/step - loss: 0.1576 - accuracy: 0.9338 - val_loss: 0.1427 - val_accuracy: 0.9379\n",
            "Epoch 4/10\n",
            "1686/1686 [==============================] - 8s 4ms/step - loss: 0.1525 - accuracy: 0.9350 - val_loss: 0.1428 - val_accuracy: 0.9373\n",
            "Epoch 5/10\n",
            "1686/1686 [==============================] - 9s 5ms/step - loss: 0.1498 - accuracy: 0.9367 - val_loss: 0.1434 - val_accuracy: 0.9387\n",
            "Epoch 6/10\n",
            "1686/1686 [==============================] - 7s 4ms/step - loss: 0.1493 - accuracy: 0.9361 - val_loss: 0.1555 - val_accuracy: 0.9383\n",
            "Epoch 7/10\n",
            "1686/1686 [==============================] - 8s 5ms/step - loss: 0.1469 - accuracy: 0.9371 - val_loss: 0.1494 - val_accuracy: 0.9385\n",
            "Epoch 8/10\n",
            "1686/1686 [==============================] - 9s 5ms/step - loss: 0.1456 - accuracy: 0.9368 - val_loss: 0.1430 - val_accuracy: 0.9370\n",
            "Epoch 9/10\n",
            "1686/1686 [==============================] - 7s 4ms/step - loss: 0.1445 - accuracy: 0.9370 - val_loss: 0.1400 - val_accuracy: 0.9373\n",
            "Epoch 10/10\n",
            "1686/1686 [==============================] - 7s 4ms/step - loss: 0.1438 - accuracy: 0.9366 - val_loss: 0.1380 - val_accuracy: 0.9385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ee820271930>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}