{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkCEGDEHYymN"
      },
      "source": [
        "import os\n",
        "os.listdir('sample_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW6XJR5PZNjE"
      },
      "source": [
        "#konversi pandas dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization -> mengubah nilai-nilai dari sebuah fitur ke dalam skala yang sama (buat mesin gampang latihan, normal kalo manusia gapaham angka angkanya)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data)\n",
        "print(scaler.transform(data))"
      ],
      "metadata": {
        "id": "7mNl2p9WOrqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standardization -> proses konversi nilai-nilai dari suatu fitur sehingga nilai-nilai tersebut memiliki skala yang sama\n",
        "#Z = value - mean / standard deviation\n",
        "from sklearn import preprocessing\n",
        "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n",
        "scaler = preprocessing.StandardScaler().fit(data)\n",
        "data = scaler.transform(data)\n",
        "data"
      ],
      "metadata": {
        "id": "BXmmokYWQXsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training set dan test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "#bagi array X dan y ke 20% data testing, sudah dirandom sebelum di split, random state digunakan supaya data konsisten\n",
        "\n",
        "X_data = range(10)\n",
        "y_data = range(10)\n",
        "\n",
        "print(\"random_state ditentukan\")\n",
        "for i in range(3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)\n",
        "  print(y_test)\n",
        "\n",
        "\n",
        "print(\"random_state tidak ditentukan\")\n",
        "for i in range(3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=None)\n",
        "  print(y_test)"
      ],
      "metadata": {
        "id": "dCtJ5_tvbjBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#latihan 2 sklearn train test split\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "\n",
        "#load datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "#pisahkan atribut dan label pada iris dataset\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "\n",
        "from sklearn .model_selection import train_test_split\n",
        "#membagi dataset menjadi training dan testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "#menghitung panjang/jumlah data pada x_test\n",
        "len(x_test) #output : 30 -> 20% dari 150"
      ],
      "metadata": {
        "id": "QGgCWggJeF4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#latihan 4 decision tree\n",
        "import pandas as pd\n",
        "\n",
        "#upload dataset ke colab\n",
        "\"\"\"from google.colab import files\n",
        "uploaded = files.upload()\"\"\"\n",
        "\n",
        "#membaca file iris.csv\n",
        "\"\"\"import io\n",
        "iris = pd.read_csv(io.BytesIO(uploaded['Iris (2).csv']))\"\"\" #key iris.csv sesuaikan nama waktu tadi upload\n",
        "iris = pd.read_csv('Iris.csv') #cara upload di colab -> bagian kiri ada file terus upload di storage session\n",
        "\n",
        "#melihat informasi dataset\n",
        "#iris.info()\n",
        "\n",
        "#melihat informasi dataset 5 baris pertama\n",
        "#iris.head()\n",
        "\n",
        "#menghilangkan kolom yang tidak penting\n",
        "iris.drop('Id',axis=1,inplace=True)\n",
        "\n",
        "#memisahkan atribut dan label\n",
        "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']] #data / atribut\n",
        "y = iris['Species'] #label\n",
        "\n",
        "#membagi dataset menjadi data latih dan uji\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
        "\n",
        "#membuat model decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "#melatih model menggunakan data latih\n",
        "tree_model = tree_model.fit(X_train, y_train)\n",
        "\n",
        "#evaluasi model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = tree_model.predict(X_test) #prediksi berdasarkan latihan yg telah dijalani\n",
        "\n",
        "acc_score = round(accuracy_score(y_pred, y_test), 3)\n",
        "\n",
        "print('Accuracy: ', acc_score)\n",
        "\n",
        "#predict model dengan tree_model_predict([[SepalLength, SepalWidth, PetalLength, PetalWidth]])\n",
        "print(tree_model.predict([[6.2, 3.4, 5.4, 2.3]])[0])\n",
        "\n",
        "#lihat visualisasi\n",
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(\n",
        "    tree_model,\n",
        "    out_file = \"iris_tree.dot\",\n",
        "    feature_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'],\n",
        "    class_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica' ],\n",
        "    rounded= True,\n",
        "    filled =True)\n",
        "#nanti di kiri muncul berkas iris_tree.dot habis itu di klik kanan + convert ke png\n",
        "#https://onlineconvertfree.com/converter/images/     buat convert ke png"
      ],
      "metadata": {
        "id": "PQx2yYJ3Aon9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#latihan 5 linear regresion\n",
        "import numpy as np\n",
        "\n",
        "#buat data jumlah kamar\n",
        "bedrooms = np.array([1,1,2,2,3,4,4,5,5,5])\n",
        "\n",
        "#data harga rumah. asumsi dalam dolar\n",
        "house_price = np.array([15000, 18000, 27000, 34000, 50000, 68000, 65000, 81000,85000, 90000])\n",
        "\n",
        "#menampilkan scatter plot dari dataset\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.scatter(bedrooms, house_price)\n",
        "\n",
        "#mulai melatih model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#latih model dengan LinearRegression.fit()\n",
        "bedrooms = bedrooms.reshape(-1,1)\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(bedrooms, house_price)\n",
        "\n",
        "#tampilkan plot hubungan antara jumlah kamar dengan harga rumah\n",
        "plt.scatter(bedrooms, house_price)\n",
        "plt.plot(bedrooms, linreg.predict(bedrooms))"
      ],
      "metadata": {
        "id": "h6gvtWermhY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#latihan 6 logistic regression\n",
        "import pandas as pd\n",
        "\n",
        "#membaca dataset dan mengubahnya jadi dataframe\n",
        "df = pd.read_csv('Social_Network_Ads.csv')\n",
        "#df.head\n",
        "\n",
        "#drop kolom yang tidak diperlukan\n",
        "data = df.drop(columns=['User ID'])\n",
        "\n",
        "#jalankan proses one hot encoding dengan pd.get_dummies()\n",
        "data = pd.get_dummies(data)\n",
        "data\n",
        "\n",
        "#pisahkan atribut dan label\n",
        "predictions = ['Age', 'EstimatedSalary', 'Gender_Female', 'Gender_Male']\n",
        "X = data[predictions]\n",
        "y = data['Purchased']\n",
        "\n",
        "#lakukan normalisasi terhadap data yang kita miliki\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "scaled_data = scaler.transform(X)\n",
        "scaled_data = pd.DataFrame(scaled_data, columns= X.columns)\n",
        "scaled_data.head()\n",
        "\n",
        "#bagi data menjadi train dan test untuk setiap atribut dan label\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2, random_state=1)\n",
        "\n",
        "#latih model dengan fungsi fit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#uji akurasi model\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc7UctNUpbSM",
        "outputId": "d902534b-aa65-4bb3-aa54-c0b5721a3b45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.825"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#latihan 7 K-means clustering\n",
        "import pandas as pd\n",
        "\n",
        "#ubah jadi dataframe\n",
        "df = pd.read_csv('Mall_Customers.csv')\n",
        "df.head(3) #lihat 3 data teratas\n",
        "\n",
        "#preprocessing manual\n",
        "#ubah nama kolom\n",
        "df = df.rename(columns={'Gender': 'gender', 'Age': 'age',\n",
        "                        'Annual Income (k$)': 'annual_income',\n",
        "                        'Spending Score (1-100)': 'spending_score'})\n",
        "\n",
        "#ubah data kategorik jadi data numerik\n",
        "df['gender'].replace(['Female', 'Male'], [0,1], inplace=True)\n",
        "\n",
        "#tampilkan data yang sudah di preprocessing\n",
        "df.head(3)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#menghilangkan kolom customerid dan gender\n",
        "X = df.drop(['CustomerID', 'gender'], axis=1)\n",
        "\n",
        "#membuat list yg berisi inertia\n",
        "clusters = []\n",
        "for i in range(1,11):\n",
        "  km = KMeans(n_clusters=i).fit(X)\n",
        "  clusters.append(km.inertia_)\n",
        "\n",
        "#buat plot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "#membuat plot inertia\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "sns.lineplot(x=list(range(1,11)), y=clusters, ax=ax)\n",
        "ax.set_title('Cari Elbow')\n",
        "ax.set_xlabel('Clusters')\n",
        "ax.set_ylabel('Inertia')\n",
        "#setelah 5 penurunannya kecil jadi elbownya 5\n",
        "\n",
        "#membuat objek KMeans\n",
        "km5 = KMeans(n_clusters=5).fit(X)\n",
        "\n",
        "#menambahkan kolom labels pada dataset\n",
        "X['Labels'] = km5.labels_\n",
        "\n",
        "#membuat plot kmeans dengan 5 klaster\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.scatterplot(x=X['annual_income'], y=X['spending_score'], hue=X['Labels'],\n",
        "                palette=sns.color_palette('hls', 5))\n",
        "plt.title('KMeans dengan 5 Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uhUH1FIE-6-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#latihan 8 sklearn PCA\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "atribut = iris.data\n",
        "label = iris.target\n",
        "\n",
        "#bagi dataset jadi train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(atribut, label, test_size=0.2, random_state=1)\n",
        "\n",
        "#pakai decision tree buat hitung score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "model_pertama = decision_tree.fit(X_train, y_train)\n",
        "model_pertama.score(X_test, y_test)\n",
        "\n",
        "#pakai pca\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#membuat objek PCA dengan 4 principal component\n",
        "pca = PCA(n_components=4)\n",
        "\n",
        "#mengaplikasikan pca pada dataset\n",
        "pca_attributes = pca.fit_transform(X_train)\n",
        "\n",
        "#melihat variance dari setiap atribut\n",
        "pca.explained_variance_ratio_\n",
        "\n",
        "#PCA dengan 2 principal component\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.fit_transform(X_test)\n",
        "\n",
        "#uji akurasi classifier\n",
        "model2 = decision_tree.fit(X_train_pca, y_train)\n",
        "model2.score(X_test_pca, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45XLlmVELQht",
        "outputId": "6746de02-d8be-46a8-9fd2-5b871464874c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}