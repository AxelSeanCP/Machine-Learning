{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Uses the same code as model to process image dataset"
      ],
      "metadata": {
        "id": "RPfL7TUTaFYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUrj0FphZ_tU",
        "outputId": "31e18b68-d200-4711-c88e-ad19a11a618b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 16:37:11--  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip [following]\n",
            "--2023-12-09 16:37:11--  https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M   290MB/s    in 0.2s    \n",
            "\n",
            "2023-12-09 16:37:11 (290 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "  -O /tmp/Chessman-image-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=0.1) # set validation split"
      ],
      "metadata": {
        "id": "hHd0UegXaPUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p87VEFAXaRXU",
        "outputId": "332399f7-4385-47b1-d437-113886a9f080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 499 images belonging to 6 classes.\n",
            "Found 52 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "model = tf.keras.models.Sequential([\n",
        "    ResNet152V2(weights='imagenet', include_top=False, input_tensor=Input(shape=(150,150,3))),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRnB_OtRaU-9",
        "outputId": "bcc30602-1cb1-4fee-d81d-83ff3b9c252b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234545216/234545216 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "DN0u9S7pbUsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              epochs=50,\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzo6z54jbhXR",
        "outputId": "e98a7ae9-651f-48f9-89b1-38f9b49a27d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 29s - loss: 7.6316 - accuracy: 0.4569 - val_loss: 2.2481 - val_accuracy: 0.5769 - 29s/epoch - 459ms/step\n",
            "Epoch 2/50\n",
            "63/63 - 9s - loss: 2.3322 - accuracy: 0.6573 - val_loss: 2.3634 - val_accuracy: 0.6538 - 9s/epoch - 144ms/step\n",
            "Epoch 3/50\n",
            "63/63 - 8s - loss: 1.1345 - accuracy: 0.7735 - val_loss: 1.5414 - val_accuracy: 0.5769 - 8s/epoch - 132ms/step\n",
            "Epoch 4/50\n",
            "63/63 - 9s - loss: 0.8557 - accuracy: 0.7996 - val_loss: 2.0977 - val_accuracy: 0.6731 - 9s/epoch - 145ms/step\n",
            "Epoch 5/50\n",
            "63/63 - 9s - loss: 0.9868 - accuracy: 0.8277 - val_loss: 1.7206 - val_accuracy: 0.6538 - 9s/epoch - 147ms/step\n",
            "Epoch 6/50\n",
            "63/63 - 9s - loss: 1.0690 - accuracy: 0.7936 - val_loss: 3.0352 - val_accuracy: 0.5577 - 9s/epoch - 137ms/step\n",
            "Epoch 7/50\n",
            "63/63 - 10s - loss: 0.8200 - accuracy: 0.8357 - val_loss: 1.1074 - val_accuracy: 0.7308 - 10s/epoch - 155ms/step\n",
            "Epoch 8/50\n",
            "63/63 - 9s - loss: 0.5295 - accuracy: 0.8878 - val_loss: 1.0628 - val_accuracy: 0.7115 - 9s/epoch - 151ms/step\n",
            "Epoch 9/50\n",
            "63/63 - 9s - loss: 0.4709 - accuracy: 0.8918 - val_loss: 1.9296 - val_accuracy: 0.7115 - 9s/epoch - 137ms/step\n",
            "Epoch 10/50\n",
            "63/63 - 8s - loss: 0.4406 - accuracy: 0.9058 - val_loss: 1.2482 - val_accuracy: 0.7308 - 8s/epoch - 124ms/step\n",
            "Epoch 11/50\n",
            "63/63 - 9s - loss: 0.4102 - accuracy: 0.9178 - val_loss: 0.7895 - val_accuracy: 0.6923 - 9s/epoch - 136ms/step\n",
            "Epoch 12/50\n",
            "63/63 - 9s - loss: 0.3043 - accuracy: 0.9339 - val_loss: 1.3592 - val_accuracy: 0.7692 - 9s/epoch - 147ms/step\n",
            "Epoch 13/50\n",
            "63/63 - 8s - loss: 0.4813 - accuracy: 0.8978 - val_loss: 0.9072 - val_accuracy: 0.8077 - 8s/epoch - 125ms/step\n",
            "Epoch 14/50\n",
            "63/63 - 9s - loss: 0.2880 - accuracy: 0.9299 - val_loss: 1.3832 - val_accuracy: 0.7885 - 9s/epoch - 147ms/step\n",
            "Epoch 15/50\n",
            "63/63 - 9s - loss: 0.2918 - accuracy: 0.9319 - val_loss: 1.3301 - val_accuracy: 0.7692 - 9s/epoch - 146ms/step\n",
            "Epoch 16/50\n",
            "63/63 - 8s - loss: 0.3989 - accuracy: 0.9098 - val_loss: 1.9541 - val_accuracy: 0.8077 - 8s/epoch - 123ms/step\n",
            "Epoch 17/50\n",
            "63/63 - 9s - loss: 0.4557 - accuracy: 0.9218 - val_loss: 1.2138 - val_accuracy: 0.8077 - 9s/epoch - 146ms/step\n",
            "Epoch 18/50\n",
            "63/63 - 9s - loss: 0.2151 - accuracy: 0.9459 - val_loss: 0.7578 - val_accuracy: 0.8077 - 9s/epoch - 149ms/step\n",
            "Epoch 19/50\n",
            "63/63 - 8s - loss: 0.3491 - accuracy: 0.9078 - val_loss: 0.4547 - val_accuracy: 0.8654 - 8s/epoch - 126ms/step\n",
            "Epoch 20/50\n",
            "63/63 - 9s - loss: 0.1908 - accuracy: 0.9559 - val_loss: 1.2263 - val_accuracy: 0.7500 - 9s/epoch - 148ms/step\n",
            "Epoch 21/50\n",
            "63/63 - 9s - loss: 0.1535 - accuracy: 0.9559 - val_loss: 0.8828 - val_accuracy: 0.8269 - 9s/epoch - 135ms/step\n",
            "Epoch 22/50\n",
            "63/63 - 8s - loss: 0.1504 - accuracy: 0.9499 - val_loss: 1.3705 - val_accuracy: 0.7115 - 8s/epoch - 126ms/step\n",
            "Epoch 23/50\n",
            "63/63 - 10s - loss: 0.1152 - accuracy: 0.9619 - val_loss: 0.8158 - val_accuracy: 0.8269 - 10s/epoch - 151ms/step\n",
            "Epoch 24/50\n",
            "63/63 - 10s - loss: 0.2449 - accuracy: 0.9439 - val_loss: 1.1166 - val_accuracy: 0.7885 - 10s/epoch - 151ms/step\n",
            "Epoch 25/50\n",
            "63/63 - 8s - loss: 0.1914 - accuracy: 0.9619 - val_loss: 1.2462 - val_accuracy: 0.7692 - 8s/epoch - 125ms/step\n",
            "Epoch 26/50\n",
            "63/63 - 9s - loss: 0.2366 - accuracy: 0.9419 - val_loss: 1.1068 - val_accuracy: 0.7692 - 9s/epoch - 150ms/step\n",
            "Epoch 27/50\n",
            "63/63 - 9s - loss: 0.1526 - accuracy: 0.9619 - val_loss: 1.2803 - val_accuracy: 0.7500 - 9s/epoch - 139ms/step\n",
            "Epoch 28/50\n",
            "63/63 - 8s - loss: 0.3826 - accuracy: 0.9259 - val_loss: 1.8040 - val_accuracy: 0.7692 - 8s/epoch - 129ms/step\n",
            "Epoch 29/50\n",
            "63/63 - 9s - loss: 0.2968 - accuracy: 0.9319 - val_loss: 1.0694 - val_accuracy: 0.8077 - 9s/epoch - 149ms/step\n",
            "Epoch 30/50\n",
            "63/63 - 9s - loss: 0.3450 - accuracy: 0.9118 - val_loss: 1.3079 - val_accuracy: 0.7692 - 9s/epoch - 150ms/step\n",
            "Epoch 31/50\n",
            "63/63 - 8s - loss: 0.2841 - accuracy: 0.9319 - val_loss: 1.8807 - val_accuracy: 0.7308 - 8s/epoch - 132ms/step\n",
            "Epoch 32/50\n",
            "63/63 - 9s - loss: 0.1334 - accuracy: 0.9459 - val_loss: 1.6173 - val_accuracy: 0.7500 - 9s/epoch - 150ms/step\n",
            "Epoch 33/50\n",
            "63/63 - 9s - loss: 0.3391 - accuracy: 0.9279 - val_loss: 0.8756 - val_accuracy: 0.7885 - 9s/epoch - 148ms/step\n",
            "Epoch 34/50\n",
            "63/63 - 8s - loss: 0.2653 - accuracy: 0.9459 - val_loss: 1.2509 - val_accuracy: 0.7308 - 8s/epoch - 130ms/step\n",
            "Epoch 35/50\n",
            "63/63 - 10s - loss: 0.3682 - accuracy: 0.9319 - val_loss: 0.8595 - val_accuracy: 0.8846 - 10s/epoch - 156ms/step\n",
            "Epoch 36/50\n",
            "63/63 - 9s - loss: 0.2317 - accuracy: 0.9439 - val_loss: 1.4173 - val_accuracy: 0.7500 - 9s/epoch - 144ms/step\n",
            "Epoch 37/50\n",
            "63/63 - 9s - loss: 0.2532 - accuracy: 0.9479 - val_loss: 0.5168 - val_accuracy: 0.8654 - 9s/epoch - 136ms/step\n",
            "Epoch 38/50\n",
            "63/63 - 10s - loss: 0.1546 - accuracy: 0.9559 - val_loss: 0.9561 - val_accuracy: 0.8462 - 10s/epoch - 152ms/step\n",
            "Epoch 39/50\n",
            "63/63 - 8s - loss: 0.2218 - accuracy: 0.9619 - val_loss: 1.9739 - val_accuracy: 0.7692 - 8s/epoch - 134ms/step\n",
            "Epoch 40/50\n",
            "63/63 - 10s - loss: 0.0947 - accuracy: 0.9659 - val_loss: 0.5066 - val_accuracy: 0.8462 - 10s/epoch - 166ms/step\n",
            "Epoch 41/50\n",
            "63/63 - 10s - loss: 0.1285 - accuracy: 0.9619 - val_loss: 1.0518 - val_accuracy: 0.7692 - 10s/epoch - 160ms/step\n",
            "Epoch 42/50\n",
            "63/63 - 9s - loss: 0.1373 - accuracy: 0.9699 - val_loss: 1.0067 - val_accuracy: 0.7885 - 9s/epoch - 145ms/step\n",
            "Epoch 43/50\n",
            "63/63 - 8s - loss: 0.1734 - accuracy: 0.9659 - val_loss: 1.0021 - val_accuracy: 0.7500 - 8s/epoch - 127ms/step\n",
            "Epoch 44/50\n",
            "63/63 - 9s - loss: 0.1756 - accuracy: 0.9659 - val_loss: 0.5860 - val_accuracy: 0.8077 - 9s/epoch - 144ms/step\n",
            "Epoch 45/50\n",
            "63/63 - 9s - loss: 0.2218 - accuracy: 0.9499 - val_loss: 0.6498 - val_accuracy: 0.8462 - 9s/epoch - 149ms/step\n",
            "Epoch 46/50\n",
            "63/63 - 8s - loss: 0.5028 - accuracy: 0.9399 - val_loss: 1.0357 - val_accuracy: 0.8269 - 8s/epoch - 134ms/step\n",
            "Epoch 47/50\n",
            "63/63 - 9s - loss: 0.2553 - accuracy: 0.9539 - val_loss: 1.0218 - val_accuracy: 0.7885 - 9s/epoch - 143ms/step\n",
            "Epoch 48/50\n",
            "63/63 - 10s - loss: 0.1721 - accuracy: 0.9619 - val_loss: 1.1951 - val_accuracy: 0.8077 - 10s/epoch - 152ms/step\n",
            "Epoch 49/50\n",
            "63/63 - 8s - loss: 0.0702 - accuracy: 0.9800 - val_loss: 0.6312 - val_accuracy: 0.8654 - 8s/epoch - 132ms/step\n",
            "Epoch 50/50\n",
            "63/63 - 8s - loss: 0.0754 - accuracy: 0.9800 - val_loss: 0.8042 - val_accuracy: 0.7885 - 8s/epoch - 128ms/step\n"
          ]
        }
      ]
    }
  ]
}